---
title: Descripcion del proyecto
jupyter: python3
---



Al operador de telecomunicaciones Interconnect le gustar√≠a poder pronosticar su tasa de cancelaci√≥n de clientes. Si se descubre que un usuario o usuaria planea irse, se le ofrecer√°n c√≥digos promocionales y opciones de planes especiales. El equipo de marketing de Interconnect ha recopilado algunos de los datos personales de sus clientes, incluyendo informaci√≥n sobre sus planes y contratos.

## Descripci√≥n de los datos

Los datos consisten en archivos obtenidos de diferentes fuentes:

- `contract.csv` ‚Äî informaci√≥n del contrato;
- `personal.csv` ‚Äî datos personales del cliente;
- `internet.csv` ‚Äî informaci√≥n sobre los servicios de Internet;
- `phone.csv` ‚Äî informaci√≥n sobre los servicios telef√≥nicos

## 1. An√°lis exploratorio de datos (EDA)

```{python}
import pandas as pd
import numpy as np
import math

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
)

from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

from sklearn.model_selection import RandomizedSearchCV
```

```{python}
# Se cargan los archivos a utilizar
df_cnt = pd.read_csv('contract.csv')
df_prs = pd.read_csv('personal.csv')
df_int = pd.read_csv('internet.csv')
df_phn = pd.read_csv('phone.csv')
```

```{python}
# Se visualiza cada archivo con el fin de entender el contenido de los mismos
df_cnt.info()
df_cnt
```

```{python}
df_prs.info()
df_prs
```

```{python}
df_int.info()
df_int
```

```{python}
df_phn.info()
df_phn
```

De momento solo se trabajar√° con este analisis exploratorio de datos. 

Se observa de momento que todos los datos que tenemos estan completos, sin embargo aun se tiene que hacer el preprocesamiento de los mismos; se debera corregir los titulos ya que no estan de acuerdo a las buenas pr√°cticas, algunas columnas hay que cambiar el tipo de datos, etc.

Posteriormente se evaluaran tambien las columnas necesarias para el analis√≠s y su distribucion

```{python}
# Unimos todos los DataFrames con base en 'df_cnt'
df_full = df_cnt.merge(df_prs, on='customerID', how='left')
df_full = df_full.merge(df_int, on='customerID', how='left')
df_full = df_full.merge(df_phn, on='customerID', how='left')
```

```{python}
# Mostramos las dimensiones del DataFrame resultante
print(df_full.shape)
df_full.head()
```

```{python}
# Creamos la variable objetivo: 1 si EndDate es distinto de 'No', 0 si sigue activo
df_full['churn'] = df_full['EndDate'].apply(lambda x: 0 if x == 'No' else 1)

# Verificamos distribuci√≥n de clases
df_full['churn'].value_counts()
```

Se tiene una proporci√≥n de aproximadamente 26.5% de churn (1869 / 7043), lo cual es un valor razonable para trabajar en clasificaci√≥n binaria, aunque hay un leve desbalance que podr√≠amos considerar m√°s adelante

```{python}
# Renombramos las columnas del DataFrame unificado
df_full.rename(columns={
    'customerID': 'customer_id',
    'BeginDate': 'begin_date',
    'EndDate': 'end_date',
    'Type': 'contract_type',
    'PaperlessBilling': 'paperless_billing',
    'PaymentMethod': 'payment_method',
    'MonthlyCharges': 'monthly_charges',
    'TotalCharges': 'total_charges',
    'gender': 'gender',
    'SeniorCitizen': 'senior_citizen',
    'Partner': 'partner',
    'Dependents': 'dependents',
    'InternetService': 'internet_service',
    'OnlineSecurity': 'online_security',
    'OnlineBackup': 'online_backup',
    'DeviceProtection': 'device_protection',
    'TechSupport': 'tech_support',
    'StreamingTV': 'streaming_tv',
    'StreamingMovies': 'streaming_movies',
    'MultipleLines': 'multiple_lines'
}, inplace=True)

df_full.columns
```

```{python}
df_full.info()
```

```{python}
df_full.describe()
```

Se observa que la columna total_charges no esta en el tipo de datos correctos

```{python}
# Convertimos total_charges a float
df_full['total_charges'] = pd.to_numeric(df_full['total_charges'], errors='coerce')

# Revisar si hubo valores no convertibles (ahora ser√°n NaN)
df_full['total_charges'].isnull().sum()
```

Ya que solo hay 11 valores nulos despues de la conversion en esta columna, se opta por eliminar las filas que contienen estos valores

```{python}
df_full = df_full[df_full['total_charges'].notna()]
df_full.shape
```

### Distribuci√≥n de variables num√©ricas

```{python}
# Lista de variables num√©ricas
num_cols = ['monthly_charges', 'total_charges']

# Histograma + boxplot para cada una
for col in num_cols:
    plt.figure(figsize=(10,4))

    # Histograma
    plt.subplot(1, 2, 1)
    sns.histplot(df_full[col], kde=True, bins=30)
    plt.title(f'Distribuci√≥n de {col}')

    # Boxplot
    plt.subplot(1, 2, 2)
    sns.boxplot(x=df_full[col])
    plt.title(f'Boxplot de {col}')

    plt.tight_layout()
    plt.show()
```

### Distribuci√≥n: monthly_charges 
- Distribuci√≥n multimodal, con varios picos.

- Posiblemente est√° reflejando distintos grupos de clientes (por ejemplo, sin servicios extra, con servicios premium, etc.).

- No hay outliers importantes, se ve bastante ‚Äúnormal‚Äù.

### Distribuci√≥n: total_charges
- Claramente sesgada a la derecha.

- Tiene varios outliers, pero es esperable: algunos clientes llevan m√°s tiempo y han pagado mucho m√°s.

```{python}
# Vamos a ver si hay diferencias claras en estas variables entre clientes que se fueron y los que no
# Comparaci√≥n de distribuci√≥n seg√∫n Churn

for col in num_cols:
    plt.figure(figsize=(8,4))
    sns.boxplot(x='churn', y=col, data=df_full)
    plt.title(f'{col} vs Churn')
    plt.xlabel('Churn')
    plt.ylabel(col)
    plt.show()
```

### monthly_charges vs churn:
- Los clientes que cancelaron (churn = 1) tienden a tener cargos mensuales m√°s altos.

- Hay una diferencia clara en las medianas ‚Üí podr√≠a ser una variable predictiva importante.

### total_charges vs churn:
- Los que se quedaron (churn = 0) tienen cargos totales m√°s altos.

- Tiene sentido: son clientes m√°s antiguos, han pagado m√°s en total.

- Tambi√©n muestra outliers ‚Äî normal considerando el largo plazo.

### An√°lisis de variables categ√≥ricas vs Churn

```{python}
cat_cols = [
    'gender', 'partner', 'dependents', 'contract_type',
    'paperless_billing', 'payment_method', 'internet_service',
    'online_security', 'online_backup', 'device_protection',
    'tech_support', 'streaming_tv', 'streaming_movies',
    'multiple_lines'
]
```

```{python}
# Cantidad de variables categ√≥ricas
n = len(cat_cols)

# Definimos filas y columnas (por ejemplo 3 columnas por fila)
cols = 3
rows = math.ceil(n / cols)

# Creamos la figura y los subplots
fig, axes = plt.subplots(rows, cols, figsize=(18, rows * 4))

# Para evitar errores si hay menos gr√°ficos que subplots
axes = axes.flatten()

# Generamos cada gr√°fico en su lugar correspondiente
for i, col in enumerate(cat_cols):
    sns.countplot(data=df_full, x=col, hue='churn', ax=axes[i])
    axes[i].set_title(f'{col} vs Churn')
    axes[i].tick_params(axis='x', rotation=45)

# Eliminamos ejes vac√≠os (si sobran)
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

```

- contract_type: Los clientes con contrato mes a mes tienen claramente mayor churn. 

- paperless_billing: Los que tienen facturaci√≥n electr√≥nica tambi√©n muestran m√°s churn.

- payment_method: El m√©todo ‚ÄúElectronic check‚Äù tiene bastante churn comparado con otros.

- online_security, online_backup, tech_support, device_protection: Quienes no tienen estos servicios tienden a cancelar m√°s. Posible se√±al de bajo compromiso o menor satisfacci√≥n.

- partner y dependents: Tener pareja o dependientes parece estar relacionado con menor churn.


```{python}
# Configuraci√≥n del gr√°fico
cols = 3
rows = math.ceil(len(cat_cols) / cols)
fig, axes = plt.subplots(rows, cols, figsize=(18, rows * 4))
axes = axes.flatten()

# Graficamos la proporci√≥n de churn para cada categor√≠a
for i, col in enumerate(cat_cols):
    churn_rate = df_full.groupby(col)['churn'].mean().sort_values(ascending=True)
    sns.barplot(x=churn_rate.values, y=churn_rate.index, ax=axes[i])
    axes[i].set_title(f'Tasa de Churn por {col}')
    axes[i].set_xlabel('Proporci√≥n de Churn')
    axes[i].set_ylabel(col)

# Eliminamos ejes vac√≠os
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()
```

- contract_type:

    - Los contratos "month-to-month" tienen la tasa de churn m√°s alta con diferencia.

    - Los contratos de 1 y 2 a√±os retienen mucho mejor.

- paperless_billing y payment_method:

    - Paperless billing = Yes ‚Üí churn m√°s alto.

    - El m√©todo "Electronic check" es el m√°s riesgoso.

    - M√©todos autom√°ticos como tarjeta o transferencia retienen mejor.

- partner y dependents:

    - Tener pareja o dependientes reduce churn ‚Üí quiz√°s porque implica mayor estabilidad/compromiso.

- Servicios de internet y adicionales (online_security, tech_support, etc.):

    - Clientes que no tienen estos servicios cancelan m√°s.

    - Probablemente reflejan menor satisfacci√≥n o menos involucramiento.

- streaming_tv y streaming_movies:

    - Relaci√≥n moderada: quienes no usan estos servicios tienen ligeramente menor churn.


###  Conclusi√≥n del EDA hasta aqu√≠
Se tiene una visi√≥n s√≥lida del comportamiento de churn seg√∫n variables:

- Las num√©ricas muestran buena diferenciaci√≥n.

- Las categ√≥ricas ofrecen pistas claras de perfiles de riesgo.

- Esto ser√° muy √∫til para feature selection y modelado m√°s adelante.

## 2. Preprocesamiento de datos

```{python}
# Se eliminar√°n las columnas innecesarias

df_model = df_full.drop(columns=[
    'customer_id',    # solo sirve como identificador
    'begin_date',     # fecha de inicio del contrato
    'end_date'        # ya fue transformada en churn
])
```

```{python}
# Codificamos todas las variables categ√≥ricas autom√°ticamente
df_model = pd.get_dummies(df_model, drop_first=True)
```

```{python}
# Instanciamos el scaler
scaler = StandardScaler()

# Columnas a escalar
num_cols = ['monthly_charges', 'total_charges']

# Aplicamos el escalado y reemplazamos en el DataFrame
df_model[num_cols] = scaler.fit_transform(df_model[num_cols])
```

## 3. Segmentaci√≥n de datos en conjuntos de entrenamiento, validaci√≥n y prueba

```{python}
# Separar X (features) e y (target)
X = df_model.drop(columns='churn')
y = df_model['churn']
```

```{python}
# Paso 1: 70% train, 30% temporal
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)

# Paso 2: 15% val, 15% test desde el 30% restante
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

# Verificamos tama√±os
print(f'Train: {X_train.shape[0]} muestras')
print(f'Validation: {X_val.shape[0]} muestras')
print(f'Test: {X_test.shape[0]} muestras')
```

Se necesitan datos para entrenar, validar y probar nuestros modelos, sin embargo, no se tiene un DF para cada cosa, por lo cual los DF que se tienen tendr√°n que ser separados en una relacion 70% de los datos para entrenamiento, 15% para la validaci√≥n y otro 15% para prueba.

## 4. Procedimiento de evaluaci√≥n

Se crea una funci√≥n para evaluar los modelos con las metricas:
- AUC-ROC
- Accuracy (exactitud)
- Precision
- Recall
- F1-score
- Matriz de confusi√≥n


```{python}
def evaluate_model(model, X_val, y_val, show_cm=True):
    # Predicci√≥n de clases
    y_pred = model.predict(X_val)

    # Predicci√≥n de probabilidades (para ROC AUC)
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_val)[:,1]
    else:
        # Algunos modelos no tienen predict_proba (como SVM sin probabilidad)
        y_prob = model.decision_function(X_val)

    # M√©tricas
    acc = accuracy_score(y_val, y_pred)
    prec = precision_score(y_val, y_pred)
    rec = recall_score(y_val, y_pred)
    f1 = f1_score(y_val, y_pred)
    auc = roc_auc_score(y_val, y_prob)

    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall:    {rec:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    print(f"AUC-ROC:   {auc:.4f}")

    if show_cm:
        cm = confusion_matrix(y_val, y_pred)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap="Blues")
        plt.title("Matriz de Confusi√≥n")
        plt.show()
```

## 5. Entrenamiento de modelo

Se entrenaran diferentes modelos con diferentes hiperpar√°metros para poder evaluarlos y elegir el mejor

### Modelo dummy

```{python}
# Creamos el modelo dummy que siempre predice la clase m√°s frecuente (estrategia = "most_frequent")
dummy = DummyClassifier(strategy="most_frequent", random_state=42)

# Entrenamos
dummy.fit(X_train, y_train)

# Evaluamos en el set de validaci√≥n
print("Evaluaci√≥n del modelo Dummy:")
evaluate_model(dummy, X_val, y_val)
```

- Accuracy alto (~73%), pero es enga√±osa: solo predice que todos los clientes se quedan (churn = 0).

- Precisi√≥n, Recall y F1 = 0 porque nunca predice la clase minoritaria (churn = 1).

- AUC = 0.5 ‚Üí equivale a tirar una moneda ü™ô (modelo sin capacidad de clasificaci√≥n real).

Este es nuestro punto de partida. Cualquier modelo √∫til deber√≠a mejorar esto.

### Regresi√≥n logistica

```{python}
# Creamos y entrenamos el modelo
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train, y_train)

# Evaluamos en el set de validaci√≥n
print("Evaluaci√≥n del modelo de Regresi√≥n Log√≠stica:")
evaluate_model(logreg, X_val, y_val)
```

- AUC-ROC de 0.84 ‚Üí muy buen resultado. El modelo es capaz de distinguir correctamente entre churn y no churn.

- Recall = 56.6% ‚Üí detecta m√°s de la mitad de los que abandonan, ¬°no est√° mal para empezar!

- Precision de 68% ‚Üí bastante decente tambi√©n.

- F1 Score equilibrado, buena se√±al de balance entre errores tipo I y II.

### Random Foerest

```{python}
# Creamos y entrenamos el modelo
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    class_weight='balanced',
    random_state=42
)
rf.fit(X_train, y_train)

# Evaluamos en el set de validaci√≥n
print("Evaluaci√≥n del modelo Random Forest:")
evaluate_model(rf, X_val, y_val)
```

Ya que se tiene un gran desempe√±o inicial con este modelo, se opta por no probar otros hiperpar√°metros. Por lo cual se procede a entrenar el siguiente modelo.

### XGBoost

```{python}
# Definimos el espacio de b√∫squeda
param_dist = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7, 10],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'scale_pos_weight': [1, 2, 3],  
}

```

```{python}
# Instanciamos el modelo base
xgb_base = XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

# Randomized search
xgb_search = RandomizedSearchCV(
    estimator=xgb_base,
    param_distributions=param_dist,
    n_iter=30,  # N√∫mero de combinaciones a probar
    scoring='roc_auc',  # Usamos AUC como criterio principal
    cv=3,  # Validaci√≥n cruzada
    verbose=1,
    random_state=42,
    n_jobs=-1
)

# Ejecutamos la b√∫squeda
xgb_search.fit(X_train, y_train)

# Mejor modelo
best_xgb = xgb_search.best_estimator_

# Evaluaci√≥n en validaci√≥n
print("Evaluaci√≥n del mejor modelo XGBoost (tuned):")
evaluate_model(best_xgb, X_val, y_val)
```

- Alta recall (82.6%): el modelo detecta a la gran mayor√≠a de los que van a cancelar, lo que es muy valioso para la empresa. Puede ofrecerles promociones, contacto preventivo, etc.

- Precision baja (49.9%): de cada 100 clientes que el modelo alerta como posibles canceladores, 51 no lo har√°n (falsos positivos). Esto podr√≠a generar esfuerzo extra en retenci√≥n innecesaria, pero muchas veces es un trade-off aceptable.

- F1 score equilibrado: indica que no est√°s sacrificando demasiado recall o precision por separado.

- AUC > 0.85: indica que el modelo distingue bien entre churn y no churn.


### LigthGBM

```{python}
# Espacio de b√∫squeda de hiperpar√°metros
param_dist_lgbm = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7, 10],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'min_child_samples': [10, 20, 30],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'class_weight': ['balanced', None]
}
```

```{python}

# Modelo base
lgbm_base = LGBMClassifier(random_state=42)

# B√∫squeda aleatoria
lgbm_search = RandomizedSearchCV(
    estimator=lgbm_base,
    param_distributions=param_dist_lgbm,
    n_iter=30,
    scoring='roc_auc',
    cv=3,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

# Entrenamiento
lgbm_search.fit(X_train, y_train)

# Evaluaci√≥n del mejor modelo
best_lgbm = lgbm_search.best_estimator_
print("Evaluaci√≥n del mejor modelo LightGBM (tuned):")
evaluate_model(best_lgbm, X_val, y_val)

```

### CatBoost

```{python}
# Definimos espacio de b√∫squeda
param_dist_cat = {
    'iterations': [200, 300, 500],
    'depth': [4, 6, 8, 10],
    'learning_rate': [0.01, 0.05, 0.1],
    'l2_leaf_reg': [1, 3, 5, 7, 9],
    'border_count': [32, 64, 128],  # puntos de partici√≥n
    'scale_pos_weight': [1, 2, 3]   # √∫til por el desbalance
}

```

```{python}
# Modelo base
cat_base = CatBoostClassifier(
    verbose=0,
    random_state=42
)

# B√∫squeda aleatoria
cat_search = RandomizedSearchCV(
    estimator=cat_base,
    param_distributions=param_dist_cat,
    n_iter=30,
    scoring='roc_auc',
    cv=3,
    random_state=42,
    verbose=1,
    n_jobs=-1
)

# Entrenamos
cat_search.fit(X_train, y_train)

# Evaluaci√≥n final
best_cat = cat_search.best_estimator_
print("Evaluaci√≥n del mejor modelo CatBoost (tuned):")
evaluate_model(best_cat, X_val, y_val)

```

- Alta precisi√≥n: si el modelo dice que un cliente va a cancelar, es muy probable que lo haga.

- AUC-ROC > 0.85: garantiza buen poder de clasificaci√≥n en general.

- Accuracy alto: el modelo hace buenas predicciones en general.

- Recall bajo: el modelo no logra detectar a todos los que se van. Se le escapan 153 churns, seg√∫n la matriz de confusi√≥n.

- Podr√≠a generar una estrategia de retenci√≥n m√°s conservadora: es decir, el equipo solo actuar√≠a sobre casos ‚Äúmuy seguros‚Äù, pero dejar√≠a ir muchos que podr√≠an haberse prevenido.

## 6. An√°lisis y evaluaci√≥n de los modelos

Se compara el rendimiento de los dos mejores modelos (XGBoost y CatBoost) sobre el conjunto de prueba.

```{python}
print("üìä Evaluaci√≥n final del modelo XGBoost (Test Set):")
evaluate_model(best_xgb, X_test, y_test)

print("\nüìä Evaluaci√≥n final del modelo CatBoost (Test Set):")
evaluate_model(best_cat, X_test, y_test)
```

- XGBoost sigue siendo el mejor para recall y F1 ‚Äî detecta m√°s churns, aunque a veces se equivoca.

- CatBoost es m√°s conservador y preciso, pero deja ir a muchos que s√≠ cancelan.

## 7. Conclusi√≥n final

Despu√©s de evaluar diversos algoritmos de clasificaci√≥n (Logistic Regression, Random Forest, XGBoost, LightGBM y CatBoost), el modelo final seleccionado fue CatBoost con hiperpar√°metros optimizados mediante RandomizedSearchCV, debido a su desempe√±o equilibrado y estabilidad en datos no vistos.

- El modelo clasifica correctamente el 78.6% de los casos.

- Con una AUC-ROC de 0.828, CatBoost demuestra ser capaz de distinguir eficazmente entre clientes que cancelan y los que no.

- La alta precisi√≥n (64.7%) indica que cuando predice que alguien se va, suele acertar.

- Aunque el recall es moderado (42.5%), este trade-off es razonable dadas las prioridades del negocio.

Este modelo puede integrarse en el sistema de CRM de la empresa para:

- Identificar posibles bajas con alta precisi√≥n.

- Ofrecer promociones, encuestas o intervenciones espec√≠ficas solo a clientes con alta probabilidad de cancelaci√≥n.

- Optimizar recursos del equipo de retenci√≥n, enfoc√°ndose en casos con mayor riesgo.



## 8. Informe de soluci√≥n

### ¬øQu√© pasos del plan se realizaron y qu√© pasos se omitieron (explica por qu√©)?

De manera general, se respetaron todos los pasos propuestos desde el inicio del proyecto. La √∫nica excepci√≥n fue el an√°lisis exploratorio de datos (EDA), el cual se desarroll√≥ con mayor profundidad. Inicialmente, se realiz√≥ una revisi√≥n general de las tablas por separado; sin embargo, posteriormente se compararon al menos dos variables con la variable objetivo (churn) para obtener una mejor comprensi√≥n del impacto de distintas caracter√≠sticas en la cancelaci√≥n del servicio.


### ¬øQu√© dificultades encontraste y c√≥mo lograste resolverlas?

Uno de los retos principales que encontr√© en este proyecto, y en la mayor√≠a, fue la correcta comprensi√≥n de la informaci√≥n. Varias partes de los datos pueden prestarse a distintas interpretaciones, o incluso pueden llegar a confundirse f√°cilmente si no se analizan con cuidado.

Por otro lado, siempre representa un reto el manejo adecuado de la informaci√≥n: c√≥mo tratarla y tener la certeza de que los datos se est√°n utilizando correctamente en cada paso del proceso.

En estos dos aspectos fue clave mantener una comunicaci√≥n efectiva con el l√≠der del equipo para aclarar dudas, adem√°s de complementar con b√∫squeda de informaci√≥n en distintas fuentes.

Finalmente, otro punto que tambi√©n representa un reto constante es el uso correcto de las librer√≠as. Algunas de ellas requieren estructuras o formatos de datos espec√≠ficos, y es f√°cil confundirse con los argumentos de ciertas funciones. En estos casos, bast√≥ con revisar la documentaci√≥n oficial de las funciones para lograr una buena interpretaci√≥n y comprensi√≥n de su funcionamiento.

### ¬øCu√°les fueron algunos de los pasos clave para resolver la tarea?

**Comprensi√≥n del problema**: Antes de trabajar con los datos, fue importante entender claramente qu√© era lo que se quer√≠a predecir (churn) y c√≥mo se iba a evaluar el modelo (AUC-ROC y accuracy como m√©tricas principales).

**Exploraci√≥n y an√°lisis de datos (EDA)**: Se realiz√≥ un an√°lisis inicial de cada tabla por separado y luego se integraron para formar un solo dataset. Se examinaron distribuciones, valores faltantes y posibles relaciones entre variables.

**Preparaci√≥n del dataset**: Incluy√≥ renombrar columnas, unificar los dataframes, crear la variable objetivo (churn), codificar variables categ√≥ricas, escalar variables num√©ricas y dividir los datos en conjuntos de entrenamiento, validaci√≥n y prueba.

**Entrenamiento de modelos**: Se probaron distintos modelos, comenzando por un DummyClassifier como referencia, luego regresi√≥n log√≠stica y varios modelos de potenciaci√≥n de gradiente como Random Forest, XGBoost, LightGBM y CatBoost.

**Optimizaci√≥n de hiperpar√°metros**: Se utiliz√≥ RandomizedSearchCV para afinar los modelos m√°s prometedores (como XGBoost, LightGBM y CatBoost) y mejorar su rendimiento.

**Evaluaci√≥n final**: Se compararon los modelos en el set de prueba, y se seleccion√≥ el que mejor cumpl√≠a con los criterios del proyecto, priorizando el AUC-ROC y la precisi√≥n general.

**Reflexi√≥n y cierre**: Finalmente, se analiz√≥ el desempe√±o del modelo, los retos encontrados en el proceso, y c√≥mo podr√≠an aplicarse los resultados en un contexto real.

### ¬øCu√°l es tu modelo final y qu√© nivel de calidad tiene?

El modelo final seleccionado fue CatBoostClassifier con hiperpar√°metros ajustados mediante RandomizedSearchCV. Esta elecci√≥n se bas√≥ en su buen desempe√±o en las dos m√©tricas principales del proyecto: AUC-ROC y accuracy.

Durante la evaluaci√≥n en el conjunto de prueba, el modelo obtuvo los siguientes resultados:

Accuracy 0.7858, AUC-ROC	0.8280, Precision	0.6467, Recall	0.4250, F1 Score	0.5129

Estos valores indican que el modelo tiene un buen poder predictivo general, siendo capaz de distinguir correctamente entre clientes que cancelan el servicio y los que no, con una precisi√≥n considerable en sus predicciones positivas. Aunque el recall fue m√°s moderado, esto representa una estrategia conservadora enfocada en minimizar los falsos positivos, lo cual puede ser √∫til si se busca aplicar acciones de retenci√≥n √∫nicamente a los casos m√°s seguros.

En resumen, el modelo final cumple con los objetivos establecidos del proyecto, entregando un rendimiento s√≥lido y equilibrado en un contexto realista.


